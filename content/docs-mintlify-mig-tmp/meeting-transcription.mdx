---
title: "automatic meeting transcription - local & private"
sidebarTitle: "meeting transcription"
description: "Automatically transcribe meetings with screenpipe. Local speech-to-text using Whisper, speaker identification, and AI-powered summaries. No cloud required."
icon: "microphone"
---

<div className="sp-audio-animation">
  <style>{`
    .sp-audio-animation {
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 2rem 0;
      gap: 2rem;
    }
    .sp-mic {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 4px;
    }
    .sp-mic-body {
      width: 24px;
      height: 40px;
      background: linear-gradient(180deg, #333 0%, #222 100%);
      border: 2px solid #555;
      border-radius: 12px 12px 12px 12px;
      position: relative;
    }
    .sp-mic-body::after {
      content: '';
      position: absolute;
      top: 8px;
      left: 50%;
      transform: translateX(-50%);
      width: 8px;
      height: 8px;
      background: #666;
      border-radius: 50%;
      animation: sp-mic-pulse 1.5s ease-in-out infinite;
    }
    @keyframes sp-mic-pulse {
      0%, 100% { background: #444; box-shadow: none; }
      50% { background: #fff; box-shadow: 0 0 10px rgba(255,255,255,0.5); }
    }
    .sp-mic-stand {
      width: 4px;
      height: 12px;
      background: #444;
    }
    .sp-mic-base {
      width: 20px;
      height: 4px;
      background: #444;
      border-radius: 2px;
    }
    .sp-waves {
      display: flex;
      align-items: center;
      gap: 4px;
      height: 50px;
    }
    .sp-wave-bar {
      width: 6px;
      background: linear-gradient(180deg, #666 0%, #333 100%);
      border-radius: 3px;
      animation: sp-wave 1s ease-in-out infinite;
    }
    .sp-wave-bar:nth-child(1) { animation-delay: 0s; height: 20px; }
    .sp-wave-bar:nth-child(2) { animation-delay: 0.1s; height: 35px; }
    .sp-wave-bar:nth-child(3) { animation-delay: 0.2s; height: 25px; }
    .sp-wave-bar:nth-child(4) { animation-delay: 0.3s; height: 45px; }
    .sp-wave-bar:nth-child(5) { animation-delay: 0.4s; height: 30px; }
    .sp-wave-bar:nth-child(6) { animation-delay: 0.5s; height: 40px; }
    .sp-wave-bar:nth-child(7) { animation-delay: 0.6s; height: 20px; }
    @keyframes sp-wave {
      0%, 100% { transform: scaleY(0.5); opacity: 0.5; }
      50% { transform: scaleY(1); opacity: 1; }
    }
    .sp-arrow-audio {
      display: flex;
      align-items: center;
      color: #555;
      font-size: 20px;
      animation: sp-arrow-pulse 1.5s ease-in-out infinite;
    }
    @keyframes sp-arrow-pulse {
      0%, 100% { opacity: 0.3; transform: translateX(0); }
      50% { opacity: 1; transform: translateX(4px); }
    }
    .sp-transcript {
      display: flex;
      flex-direction: column;
      gap: 6px;
      padding: 12px;
      background: #111;
      border: 1px solid #333;
      border-radius: 8px;
      min-width: 120px;
    }
    .sp-transcript-line {
      height: 4px;
      background: #444;
      border-radius: 2px;
      animation: sp-type 2s ease-out infinite;
    }
    .sp-transcript-line:nth-child(1) { width: 80px; animation-delay: 0s; }
    .sp-transcript-line:nth-child(2) { width: 100px; animation-delay: 0.3s; }
    .sp-transcript-line:nth-child(3) { width: 60px; animation-delay: 0.6s; }
    @keyframes sp-type {
      0% { width: 0; opacity: 0; }
      20% { opacity: 1; }
      100% { opacity: 1; }
    }
  `}</style>

  <div className="sp-mic">
    <div className="sp-mic-body"></div>
    <div className="sp-mic-stand"></div>
    <div className="sp-mic-base"></div>
  </div>

  <div className="sp-waves">
    <div className="sp-wave-bar"></div>
    <div className="sp-wave-bar"></div>
    <div className="sp-wave-bar"></div>
    <div className="sp-wave-bar"></div>
    <div className="sp-wave-bar"></div>
    <div className="sp-wave-bar"></div>
    <div className="sp-wave-bar"></div>
  </div>

  <div className="sp-arrow-audio">â†’</div>

  <div className="sp-transcript">
    <div className="sp-transcript-line"></div>
    <div className="sp-transcript-line"></div>
    <div className="sp-transcript-line"></div>
  </div>
</div>

screenpipe automatically transcribes all audio from your meetings, calls, and conversations. everything runs locally using Whisper for maximum privacy.

## how it works

1. **audio capture**: screenpipe records from your microphone and system audio
2. **speech-to-text**: audio is transcribed using Whisper (runs locally)
3. **speaker identification**: different speakers are automatically labeled
4. **searchable storage**: transcripts are indexed and searchable

## setup

### basic setup

```bash
# start screenpipe with audio enabled (default)
screenpipe
```

### capture both mic and system audio

```bash
# list available audio devices
screenpipe --list-audio-devices

# capture specific devices
screenpipe --audio-device "MacBook Pro Microphone" --audio-device "BlackHole 2ch"
```

### choose transcription engine

```bash
# local (default) - most private
screenpipe --audio-transcription-engine whisper-large-v3-turbo

# cloud - faster, requires API key
screenpipe --audio-transcription-engine deepgram
```

## query transcriptions

```typescript
import { pipe } from "@screenpipe/js";

// find discussions about a topic
const results = await pipe.queryScreenpipe({
  q: "budget review",
  contentType: "audio",
  limit: 10
});

// get transcripts from today's meetings
const today = new Date().toISOString().split('T')[0];
const meetings = await pipe.queryScreenpipe({
  startTime: today,
  contentType: "audio"
});
```

## using the meeting pipe

for automatic meeting summaries:

1. install the **meeting** pipe from [GitHub](https://github.com/mediar-ai/screenpipe/tree/main/pipes/meeting)
2. it automatically detects when meetings start
3. generates summaries with action items
4. can sync to Notion, Obsidian, or other tools

## transcription quality tips

- use a good microphone
- reduce background noise
- `whisper-large-v3-turbo` gives best accuracy
- add `--language en` if you only speak English (faster)

## speaker identification

screenpipe automatically identifies different speakers:

```typescript
const results = await pipe.queryScreenpipe({
  contentType: "audio"
});

for (const item of results.data) {
  if (item.type === "Audio") {
    console.log(`Speaker ID: ${item.content.speaker_id}`);
    console.log(`Speaker Name: ${item.content.speaker?.name || "Unknown"}`);
    console.log(`Text: ${item.content.transcription}`);
  }
}
```

### filter by speaker

```typescript
// filter by specific speaker IDs
const results = await pipe.queryScreenpipe({
  contentType: "audio",
  speakerIds: [1, 2, 3]
});

// or use the REST API directly
// GET http://localhost:3030/search?content_type=audio&speaker_ids=1,2,3
// GET http://localhost:3030/search?content_type=audio&speaker_name=John
```

### speaker management API

screenpipe provides REST endpoints to manage speakers:

| endpoint | method | description |
|----------|--------|-------------|
| `/speakers/unnamed` | GET | get speakers without names assigned |
| `/speakers/search?name=query` | GET | search speakers by name |
| `/speakers/update` | POST | update speaker name or metadata |
| `/speakers/merge` | POST | merge two speaker profiles |
| `/speakers/reassign` | POST | reassign audio chunk to different speaker |
| `/speakers/similar?speaker_id=1` | GET | find similar speakers |
| `/speakers/delete` | POST | delete a speaker profile |
| `/speakers/hallucination` | POST | mark speaker as false detection |

### update speaker name

```bash
# update a speaker's name
curl -X POST http://localhost:3030/speakers/update \
  -H "Content-Type: application/json" \
  -d '{"id": 1, "name": "John Smith"}'
```

### search speakers

```bash
# find speakers by name prefix
curl "http://localhost:3030/speakers/search?name=john"

# get unnamed speakers for labeling
curl "http://localhost:3030/speakers/unnamed?limit=10&offset=0"
```

### merge duplicate speakers

```bash
# merge speaker 2 into speaker 1
curl -X POST http://localhost:3030/speakers/merge \
  -H "Content-Type: application/json" \
  -d '{"speaker_to_keep_id": 1, "speaker_to_merge_id": 2}'
```

### reassign audio to different speaker

```bash
# reassign an audio chunk to a named speaker
curl -X POST http://localhost:3030/speakers/reassign \
  -H "Content-Type: application/json" \
  -d '{
    "audio_chunk_id": 123,
    "new_speaker_name": "Jane Doe",
    "propagate_similar": true
  }'
```

## privacy

- all transcription runs locally on your device
- audio files stored in `~/.screenpipe/data/`
- no audio is sent to the cloud (unless you choose deepgram)
- you can disable audio recording with `--disable-audio`

## next steps

- [install screenpipe](/getting-started)
- [CLI audio options](/cli-reference#audio-options)
- [build a meeting notes plugin](/plugins)
