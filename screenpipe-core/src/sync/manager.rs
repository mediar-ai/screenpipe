//! High-level sync manager for coordinating sync operations.
//!
//! This module provides a simple interface for common sync operations,
//! handling the encryption/decryption and API communication internally.

use std::sync::Arc;
use tokio::sync::RwLock;

use super::blob::{decrypt_blob, encrypt_blob, BlobMetadata, BlobType, DecryptedBlob};
use super::client::{
    DownloadBlob, DownloadRequest, SearchRequest, SyncClient, SyncClientConfig, SyncStatus,
    TimeRange,
};
use super::crypto::generate_search_token;
use super::error::{SyncError, SyncResult};
use super::keys::SyncKeys;

/// High-level manager for sync operations.
///
/// This struct holds the sync client and encryption keys, providing
/// a simple interface for uploading, downloading, and searching data.
pub struct SyncManager {
    client: SyncClient,
    keys: Arc<RwLock<Option<SyncKeys>>>,
}

impl SyncManager {
    /// Create a new sync manager.
    pub fn new(config: SyncClientConfig) -> SyncResult<Self> {
        let client = SyncClient::new(config)?;
        Ok(Self {
            client,
            keys: Arc::new(RwLock::new(None)),
        })
    }

    /// Check if the manager is initialized (has keys).
    pub async fn is_initialized(&self) -> bool {
        self.keys.read().await.is_some()
    }

    /// Initialize sync with the user's password.
    ///
    /// This will either create new encryption keys (for new users) or
    /// derive keys from the server's stored encrypted master key.
    ///
    /// Returns true if this is a new user, false if existing.
    pub async fn initialize(&self, password: &str) -> SyncResult<bool> {
        let (keys, is_new) = self.client.init(password).await?;
        *self.keys.write().await = Some(keys);
        Ok(is_new)
    }

    /// Lock the manager (clear keys from memory).
    ///
    /// Call this when the user logs out or the app is locked.
    pub async fn lock(&self) {
        *self.keys.write().await = None;
    }

    /// Get a reference to the keys, or error if not initialized.
    async fn require_keys(&self) -> SyncResult<tokio::sync::RwLockReadGuard<'_, Option<SyncKeys>>> {
        let guard = self.keys.read().await;
        if guard.is_none() {
            return Err(SyncError::Key("sync not initialized".to_string()));
        }
        Ok(guard)
    }

    // =========================================================================
    // Upload Operations
    // =========================================================================

    /// Upload data to the cloud.
    ///
    /// This encrypts the data locally and uploads it to S3.
    ///
    /// # Arguments
    /// * `data` - The plaintext data to upload
    /// * `blob_type` - The type of data
    /// * `time_start` - Start of time range (ISO 8601)
    /// * `time_end` - End of time range (ISO 8601)
    /// * `text_content` - Optional text for search indexing
    ///
    /// # Returns
    /// The blob ID and updated storage usage
    pub async fn upload(
        &self,
        data: &[u8],
        blob_type: BlobType,
        time_start: &str,
        time_end: &str,
        text_content: Option<&str>,
    ) -> SyncResult<UploadResult> {
        let keys_guard = self.require_keys().await?;
        let keys = keys_guard.as_ref().unwrap();

        // Encrypt the data
        let encrypted = encrypt_blob(data, blob_type, keys, text_content)?;

        // Create metadata
        let metadata = BlobMetadata::from_encrypted_blob(
            &encrypted,
            time_start,
            time_end,
            keys.key_version(),
        );

        // Request upload URL
        let upload_info = self.client.request_upload(&metadata).await?;

        // Upload to S3
        self.client
            .upload_to_s3(&upload_info.upload_url, &encrypted.ciphertext)
            .await?;

        // Mark upload complete
        let complete = self.client.complete_upload(&upload_info.blob_id).await?;

        Ok(UploadResult {
            blob_id: upload_info.blob_id,
            storage_used: complete.storage_used,
            storage_limit: complete.storage_limit,
        })
    }

    // =========================================================================
    // Download Operations
    // =========================================================================

    /// Download and decrypt blobs by ID.
    pub async fn download_by_ids(&self, blob_ids: Vec<String>) -> SyncResult<Vec<DecryptedBlob>> {
        let keys_guard = self.require_keys().await?;
        let keys = keys_guard.as_ref().unwrap();

        let request = DownloadRequest {
            blob_ids: Some(blob_ids),
            time_range: None,
            blob_types: None,
            limit: None,
        };

        let blobs = self.client.get_download_urls(request).await?;
        self.download_and_decrypt_blobs(&blobs, keys).await
    }

    /// Download and decrypt blobs by time range.
    pub async fn download_by_time_range(
        &self,
        start: Option<String>,
        end: Option<String>,
        blob_types: Option<Vec<BlobType>>,
        limit: Option<u32>,
    ) -> SyncResult<Vec<DecryptedBlob>> {
        let keys_guard = self.require_keys().await?;
        let keys = keys_guard.as_ref().unwrap();

        let request = DownloadRequest {
            blob_ids: None,
            time_range: Some(TimeRange { start, end }),
            blob_types,
            limit,
        };

        let blobs = self.client.get_download_urls(request).await?;
        self.download_and_decrypt_blobs(&blobs, keys).await
    }

    async fn download_and_decrypt_blobs(
        &self,
        blobs: &[DownloadBlob],
        keys: &SyncKeys,
    ) -> SyncResult<Vec<DecryptedBlob>> {
        let mut results = Vec::with_capacity(blobs.len());

        for blob in blobs {
            // Download from S3
            let ciphertext = self.client.download_from_s3(&blob.download_url).await?;

            // Decrypt
            let decrypted = decrypt_blob(
                &ciphertext,
                &blob.encryption_nonce,
                Some(&blob.checksum),
                blob.blob_type,
                keys,
            )?;

            results.push(decrypted);
        }

        Ok(results)
    }

    // =========================================================================
    // Search Operations
    // =========================================================================

    /// Search for blobs containing the given keywords.
    ///
    /// This generates search tokens from the keywords and searches the
    /// encrypted index on the server.
    pub async fn search(
        &self,
        keywords: &[&str],
        time_range: Option<TimeRange>,
        blob_types: Option<Vec<BlobType>>,
        limit: Option<u32>,
    ) -> SyncResult<SearchResult> {
        let keys_guard = self.require_keys().await?;
        let keys = keys_guard.as_ref().unwrap();

        // Generate search tokens
        let mut tokens = Vec::with_capacity(keywords.len());
        for keyword in keywords {
            let token = generate_search_token(keyword, keys.search_key())?;
            tokens.push(base64::engine::general_purpose::STANDARD.encode(token));
        }

        use base64::Engine;

        let request = SearchRequest {
            search_tokens: tokens,
            time_range,
            blob_types,
            limit,
        };

        let response = self.client.search(request).await?;

        Ok(SearchResult {
            blob_ids: response.matches.iter().map(|m| m.blob_id.clone()).collect(),
            matches: response.matches.into_iter().map(|m| SearchMatchInfo {
                blob_id: m.blob_id,
                blob_type: m.blob_type,
                time_start: m.time_start,
                time_end: m.time_end,
                match_count: m.match_count,
            }).collect(),
            total: response.total_matches,
        })
    }

    /// Search and download matching blobs.
    ///
    /// Convenience method that combines search + download.
    pub async fn search_and_download(
        &self,
        keywords: &[&str],
        time_range: Option<TimeRange>,
        blob_types: Option<Vec<BlobType>>,
        limit: Option<u32>,
    ) -> SyncResult<Vec<DecryptedBlob>> {
        let search_result = self.search(keywords, time_range, blob_types, limit).await?;

        if search_result.blob_ids.is_empty() {
            return Ok(Vec::new());
        }

        self.download_by_ids(search_result.blob_ids).await
    }

    // =========================================================================
    // Status Operations
    // =========================================================================

    /// Get sync status and quota information.
    pub async fn get_status(&self) -> SyncResult<SyncStatus> {
        self.client.get_status().await
    }

    /// Get the client for advanced operations.
    pub fn client(&self) -> &SyncClient {
        &self.client
    }
}

/// Result of an upload operation.
#[derive(Debug)]
pub struct UploadResult {
    /// The blob ID assigned by the server
    pub blob_id: String,
    /// Current storage used in bytes
    pub storage_used: u64,
    /// Storage limit in bytes
    pub storage_limit: u64,
}

/// Result of a search operation.
#[derive(Debug)]
pub struct SearchResult {
    /// Matching blob IDs
    pub blob_ids: Vec<String>,
    /// Detailed match information
    pub matches: Vec<SearchMatchInfo>,
    /// Total number of matches
    pub total: u32,
}

/// Information about a search match.
#[derive(Debug)]
pub struct SearchMatchInfo {
    /// Blob ID
    pub blob_id: String,
    /// Blob type
    pub blob_type: BlobType,
    /// Start of time range
    pub time_start: String,
    /// End of time range
    pub time_end: String,
    /// Number of matching tokens
    pub match_count: u32,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_upload_result() {
        let result = UploadResult {
            blob_id: "blob-123".to_string(),
            storage_used: 1024,
            storage_limit: 1024 * 1024,
        };
        assert_eq!(result.blob_id, "blob-123");
    }

    #[test]
    fn test_search_result() {
        let result = SearchResult {
            blob_ids: vec!["blob-1".to_string(), "blob-2".to_string()],
            matches: vec![],
            total: 2,
        };
        assert_eq!(result.blob_ids.len(), 2);
        assert_eq!(result.total, 2);
    }
}
